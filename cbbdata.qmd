---
title: "Predicting Duke vs. UNC Feb. 3, 2023 using modeling"
format: html
editor: visual
author: "Dom Fenoglio, The Duke Chronicle"
---

```{r loading packages, include=FALSE}
# first, install cbbdata package and create your own login, or else none of the
# code below will work
cbbdata::cbd_login()
library(cbbdata)
library(tidyverse)
library(tidymodels)
library(caret)
```

```{r getting Duke data, include=FALSE}
duke_data <- cbd_torvik_game_factors() %>% 
  filter(team == 'Duke')
```

# What is the game prediction?

```{r simulating Duke UNC game for feb 2024, echo=FALSE}
duke_unc_game <- cbd_torvik_season_prediction('Duke',2024) %>% 
  filter(opp == 'North Carolina', game_location == 'A')
duke_unc_game
unc_duke_game <- cbd_torvik_season_prediction('North Carolina',2024) %>% 
  filter(opp == 'Duke', game_location == 'H')
unc_duke_game

result <- rbinom(100, 1, 0.22332)

single_game_pred <- as.data.frame(result) 

single_game_pred %>% 
  ggplot(aes(x = result)) +
  geom_histogram(binwidth = 0.5, fill = "#003087") +
  labs(title = "100 simulations of Duke vs. UNC",
       subtitle = "Using probability 0.22332 for a Duke win",
       x = "Result (1 = Duke win, 0 = UNC win)",
       y = "Count")
```

This is a simple representation of 100 simulations of a binomial trial with the given probability of Duke winning. In other words, if the game was played 100 times, these would be the results. Clearly, the Tar Heels are going to run away with this one. But, this is just a surface level look at the data, so let's look closer.

```{r collecting data from all Duke UNC games 2015-2023, include=FALSE}
home_games <- list("20150218","20160305","20170209","20180303",
                   "20190220","20200307","20210206","20220305","20230204")
away_games <- list("20150307","20160217","20170304","20180208",
                   "20190309","20200208","20210306","20220205","20230304")
home_predictions <- cbd_torvik_game_prediction('Duke','North Carolina',
                                               "20150218")
for (x in home_games){
  this_pred = cbd_torvik_game_prediction('Duke','North Carolina', x)
  home_predictions = full_join(home_predictions, this_pred)
}
away_predictions <- cbd_torvik_game_prediction('North Carolina', 
                                               'Duke', "20150307")
for (x in away_games){
  this_pred = cbd_torvik_game_prediction('North Carolina','Duke', x)
  away_predictions = full_join(away_predictions, this_pred)
}

full_predictions <- full_join(home_predictions, away_predictions)
```

```{r recording box score data from those games, include=FALSE}
date <- c("02/17/2015","03/06/2015","02/16/2016","03/04/2016",
          "02/08/2017","03/03/2017","02/07/2018","03/02/2018",
          "02/19/2019","03/08/2019","02/07/2020","03/06/2020",
          "02/05/2021","03/05/2021","02/04/2022","03/04/2022",
          "02/03/2023","03/03/2023")
date <- as.Date(date, format = "%m/%d/%Y")
winner <- c("Duke","Duke","Duke","North Carolina","Duke",
            "North Carolina","North Carolina","Duke",
            "North Carolina","North Carolina","Duke","Duke",
            "North Carolina","North Carolina","Duke",
            "North Carolina","Duke","Duke")
diff <- c(2,7,1,-4,8,-7,-4,10,-16,-9,2,13,-4,-18,20,-13,6,5)
duke_home <- c("Home","Away","Away","Home","Home","Away",
               "Away","Home","Home","Away","Away","Home",
               "Home","Away","Away","Home","Home","Away")
real_results <- data.frame(date,winner,diff,duke_home)
```

# Some exploratory analysis

```{r showing projected vs actual point differential, echo=FALSE}
full_predictions <- full_predictions %>% 
  mutate(duke_home = case_when(team == "Duke" & location == "H"  ~ "Home",
                               team == "North Carolina" & location == "A" ~ "Home",
                               TRUE ~ "Away"),
         duke_pts = if_else(team == "Duke", pts, 0),
         unc_pts = if_else(team == "North Carolina",pts,0))

full_predictions <- full_predictions %>% 
  group_by(date) %>% 
  mutate(diff = max(duke_pts) - max(unc_pts))


full_predictions %>% 
  filter(team == "Duke") %>% 
  ggplot(aes(x = date, y = diff, color = duke_home)) +
  geom_point() +
  geom_hline(yintercept =  0, linetype = 2) +
  facet_wrap(~ duke_home) +
  labs(title = "Projected point differential of Duke vs. UNC",
       subtitle = "From 2015-2023",
       y = "Duke points minus UNC points",
       x = "Time",
       color = "location")
real_results %>% 
  ggplot(aes(x = date, y = diff, color = duke_home)) +
  geom_point() +
  geom_hline(yintercept =  0, linetype = 2) +
  facet_wrap(~ duke_home) +
  labs(title = "Actual point differential of Duke vs. UNC",
       subtitle = "From 2015-2023",
       y = "Duke points minus UNC points",
       x = "Time",
       color = "location")
```

These graphs allow you to see the vast difference between projected point differentials and actual game scores. In particular, notice the blue dot dated right after 2022. This was Coach K's final home game. An unranked North Carolina team beat No. 9 Duke in a decisive 13-point victory. On the whole, the predictions can get really far off. Maybe it's just hard to predict basketball games (it is), and the model can't do much.

```{r getting Duke ACC predictions, include=FALSE}
acc_2023 <- full_join(cbd_torvik_season_prediction("Duke", 2023,"20230101"),duke_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

acc_2022 <- full_join(cbd_torvik_season_prediction("Duke", 2022,"20220101"),duke_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

test <- full_join(acc_2023,acc_2022)

acc_2021 <- full_join(cbd_torvik_season_prediction("Duke", 2021,"20210101"),duke_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

test <- full_join(test,acc_2021)

acc_2020 <- full_join(cbd_torvik_season_prediction("Duke", 2020,"20200101"),duke_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

test <- full_join(test,acc_2020)

duke_final <- test %>% 
  mutate(diff = pts_scored - pts_allowed,
         projection = case_when(win_per > 50  ~ "Projected Win", 
                  win_per <50 ~ "Projected Loss", 
                   TRUE ~ "Too close to call")) %>% 
  filter(!is.na(win_per))

```

```{r getting UNC predictions, include=FALSE}
unc_data <- cbd_torvik_game_factors() %>% 
  filter(team == 'North Carolina')

acc_2023_unc <- full_join(cbd_torvik_season_prediction("North Carolina", 2023, date = "20230101"),unc_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

acc_2022_unc <- full_join(cbd_torvik_season_prediction("North Carolina", 2022, "20220101"),unc_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

test_unc <- full_join(acc_2023_unc,acc_2022_unc)

acc_2021_unc <- full_join(cbd_torvik_season_prediction("North Carolina", 2021, "20210101"),unc_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

test_unc <- full_join(test_unc,acc_2021_unc)

acc_2020_unc <- full_join(cbd_torvik_season_prediction("North Carolina", 2020, "20200101"),unc_data, by = join_by(date)) %>% 
  select(-location, -avg_marg) %>% 
  filter(! is.na(pts_scored), opp_conf == "ACC", !is.na(team.x))

test_unc <- full_join(test_unc,acc_2020_unc)

unc_final <- test_unc %>% 
  mutate(diff = pts_scored - pts_allowed,
         projection = case_when(win_per > 50  ~ "Projected Win", 
                  win_per <50 ~ "Projected Loss", 
                   TRUE ~ "Too close to call")) %>% 
  filter(!is.na(win_per), team.x == "North Carolina")

```

```{r conf_matrix for just duke, include=FALSE}
#library(caret)

conf_mat_data <- duke_final %>% 
  #filter(projection != "Too close to call") %>% 
  mutate(projection_bin = fct_relevel(as.factor(if_else(projection == "Projected Win", 1, 0)), "1"),
         result_bin = fct_relevel(as.factor(if_else(result == "W", 1, 0))),"1")
conf_matrix <- confusionMatrix(data=conf_mat_data$projection_bin, reference = conf_mat_data$result_bin, positive = "1")
conf_matrix
```

```{r conf_matrix for just unc, include=FALSE}
conf_mat_data_unc <- unc_final %>% 
  filter(projection != "Too close to call") %>% 
  mutate(projection_bin = fct_relevel(as.factor(if_else(projection == "Projected Win", 1, 0)), "1"),
         result_bin = fct_relevel(as.factor(if_else(result == "W", 1, 0))),"1")
conf_matrix_unc <- confusionMatrix(data=conf_mat_data_unc$projection_bin, reference = conf_mat_data_unc$result_bin, positive = "1")
conf_matrix_unc
```

# Duke and UNC ACC games 2020-2023

```{r graph and conf_matrix for both teams, echo=FALSE,message=FALSE, warning=FALSE}
both_teams <- full_join(duke_final,unc_final)

both_teams %>% 
  ggplot(aes(x = win_per, y = diff, color = projection, shape = team.x)) +
  geom_hline(yintercept =  0, linetype = 1) +
  geom_vline(xintercept = 50, linetype = 2) +
  geom_point(size = 3, alpha = 0.75) +
  theme_minimal() +
  labs(title = "Duke and UNC's ACC wins and losses from 2020-23",
       subtitle = "Comparing projected win probability to actual point difference",
       shape = "",
       x = "Win probability (%)",
       y = "Actual point differential")

conf_mat_data_combo <- both_teams %>% 
  mutate(projection_bin = fct_relevel(as.factor(if_else(projection == "Projected Win", 1, 0)), "1"),
         result_bin = fct_relevel(as.factor(if_else(result == "W", 1, 0))),"1")
conf_matrix_combo <- confusionMatrix(data=conf_mat_data_combo$projection_bin, reference = conf_mat_data_combo$result_bin, positive = "1")
conf_matrix_combo
```

This graph allows us to see the distribution of Duke and North Carolina's ACC games from the past few years, and how the model did at predicting the outcome. On the whole, it did a pretty good job, as shown by the confusion matrix analysis. Our confusion matrix gave a significant p-value of 0.001546, a positive predictive of 72.03% and a negative predictive value of 69.44%. Great! Then, it should be able to be just effective at predicting Duke vs. UNC, right?

# Now, let's see the past 8 years of the Rivalry

```{r graph for Duke UNC games, echo=FALSE}
real_results <- real_results %>% 
  mutate(bin_win = as.factor(if_else(diff > 0, 1,0)))

full_predictions <- full_predictions %>% 
  mutate(bin_win = as.factor(if_else(diff > 0, 1,0)))

joined_pred_real <- full_join(real_results,full_predictions, by = join_by(date))

joined_pred_real %>% 
  mutate(win_cat = fct_relevel(if_else(bin_win.x == 1, "Win", "Loss"),"Win")) %>% 
  filter(team == "Duke") %>% 
  ggplot(aes(x=win_per,y=diff.x,color = win_cat, shape = duke_home.x)) +
  #facet_wrap(~ duke_home.x) +
  geom_point(size = 4) +
  scale_color_manual(values = c("#003087","#62C6F2")) +
  geom_hline(yintercept = 0, linetype = 1) +
  geom_vline(xintercept = 50, linetype = 2) +
  theme_minimal() +
  labs(title = "Duke and UNC's wins and losses against\neach other from 2015-2023",
       subtitle = "Comparing projected win probability to actual point difference",
       x = "Predicted Duke win probability (%)",
       y = "Actual point differential",
       color = "Did Duke win?",
       shape = "Where is the game?")
```

This graph breaks down win probability versus actual results, with coloring showing which shade of blue won. A quick look at this graph shows that our model didn't do a very great job. Why are these games so far off if on the whole it does a good job? Again, let's look closer.

```{r conf_matrix for Duke_UNC games, echo=FALSE, message=FALSE,warning=FALSE}
filtered_predictions <- full_predictions %>% 
  filter(team == "Duke")

confusionMatrix(data=filtered_predictions$bin_win, reference = real_results$bin_win, positive = "1")
```

In fact, this data does not tell us much about the true outcome of the game at all. Positive and negative predictive values are low, and we might be better off just flipping a coin. While we can't create any concrete reasons why solely from this data, we can conclude that this model does not consistently provide an accurate prediction.

# Conclusions

In my own humble opinion, this game is the best rivalry in sports. Every piece of data can be thrown out the window when it comes to these two schools, and instead of trying to jump to any conclusions, we're better off just going along for the ride. My full article breaking down these findings in a more compact, thorough way can be found on dukechronicle.com.